{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AnnotatedImage' object has no attribute 'change'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 99\u001b[0m\n\u001b[0;32m     92\u001b[0m load_btn\u001b[38;5;241m.\u001b[39mclick(\n\u001b[0;32m     93\u001b[0m     fn\u001b[38;5;241m=\u001b[39mconfigure_window,\n\u001b[0;32m     94\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[window_dropdown, use_ocr],\n\u001b[0;32m     95\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[annotated_img]\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Update bounding boxes when user edits\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mannotated_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchange\u001b[49m(\n\u001b[0;32m    100\u001b[0m     fn\u001b[38;5;241m=\u001b[39mupdate_boxes,\n\u001b[0;32m    101\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[annotated_img, annotated_img],\n\u001b[0;32m    102\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mannotated_img\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Save configuration on button click\u001b[39;00m\n\u001b[0;32m    106\u001b[0m save_btn\u001b[38;5;241m.\u001b[39mclick(\n\u001b[0;32m    107\u001b[0m     fn\u001b[38;5;241m=\u001b[39msave_configuration,\n\u001b[0;32m    108\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[annotated_img, gr\u001b[38;5;241m.\u001b[39mTextbox(value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[0;32m    109\u001b[0m     outputs\u001b[38;5;241m=\u001b[39msave_output\n\u001b[0;32m    110\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AnnotatedImage' object has no attribute 'change'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pygetwindow as gw\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import easyocr\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Initialize OCR Reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Function to capture screenshot of a selected window\n",
    "def capture_screenshot(window_title):\n",
    "    windows = gw.getWindowsWithTitle(window_title)\n",
    "    if not windows:\n",
    "        raise ValueError(f\"Window with title '{window_title}' not found.\")\n",
    "    \n",
    "    window = windows[0]\n",
    "    if window.isMinimized:\n",
    "        window.restore()\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    try:\n",
    "        window.activate()\n",
    "        time.sleep(0.5)\n",
    "        x, y, width, height = window.left, window.top, window.width, window.height\n",
    "        screenshot = pyautogui.screenshot(region=(x, y, width, height))\n",
    "        return screenshot, (x, y, width, height)\n",
    "    except gw.PyGetWindowException as e:\n",
    "        raise RuntimeError(f\"Failed to activate window '{window_title}': {e}\")\n",
    "\n",
    "# Function to apply OCR and get initial bounding boxes\n",
    "def apply_ocr(img, use_ocr=True):\n",
    "    if use_ocr:\n",
    "        img_np = np.array(img)\n",
    "        bounds = reader.readtext(img_np)\n",
    "        boxes = []\n",
    "        for bound in bounds:\n",
    "            top_left, bottom_right = tuple(bound[0][0]), tuple(bound[0][2])\n",
    "            boxes.append({\n",
    "                \"label\": \"OCR Box\",\n",
    "                \"x\": top_left[0],\n",
    "                \"y\": top_left[1],\n",
    "                \"width\": bottom_right[0] - top_left[0],\n",
    "                \"height\": bottom_right[1] - top_left[1]\n",
    "            })\n",
    "        return img, boxes\n",
    "    else:\n",
    "        return img, []\n",
    "\n",
    "# Function to update bounding boxes and redraw them on the image\n",
    "def update_boxes(image, boxes):\n",
    "    img = image.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes:\n",
    "        x, y, width, height = box[\"x\"], box[\"y\"], box[\"width\"], box[\"height\"]\n",
    "        draw.rectangle([x, y, x + width, y + height], outline=\"red\", width=2)\n",
    "    return img\n",
    "\n",
    "# Function to retrieve open windows and load initial screenshot with OCR boxes\n",
    "def configure_window(window_title, use_ocr):\n",
    "    screenshot, window_size = capture_screenshot(window_title)\n",
    "    processed_img, boxes = apply_ocr(screenshot, use_ocr)\n",
    "    return processed_img, boxes\n",
    "\n",
    "# Save configuration function\n",
    "def save_configuration(boxes, filename):\n",
    "    config = {\n",
    "        \"boxes\": boxes\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(config, f)\n",
    "    return f\"Configuration saved to {filename}\"\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Bounding Box Annotation\"):\n",
    "        # Dropdown to select open windows\n",
    "        window_dropdown = gr.Dropdown(choices=[w.title for w in gw.getAllTitles() if w], label=\"Select a Window\")\n",
    "        use_ocr = gr.Checkbox(label=\"Use OCR for Bounding Boxes\", value=True)\n",
    "        load_btn = gr.Button(\"Load Screenshot\")\n",
    "\n",
    "        # AnnotatedImage to display and interact with bounding boxes\n",
    "        annotated_img = gr.AnnotatedImage(label=\"Screenshot with Bounding Boxes\")\n",
    "\n",
    "        # Button to save configuration\n",
    "        save_btn = gr.Button(\"Save Configuration\")\n",
    "        save_output = gr.Textbox(label=\"Save Output\")\n",
    "\n",
    "        # Load screenshot and apply OCR bounding boxes\n",
    "        load_btn.click(\n",
    "            fn=configure_window,\n",
    "            inputs=[window_dropdown, use_ocr],\n",
    "            outputs=[annotated_img]\n",
    "        )\n",
    "\n",
    "        # Update bounding boxes when user edits\n",
    "        annotated_img.change(\n",
    "            fn=update_boxes,\n",
    "            inputs=[annotated_img, annotated_img],\n",
    "            outputs=annotated_img\n",
    "        )\n",
    "\n",
    "        # Save configuration on button click\n",
    "        save_btn.click(\n",
    "            fn=save_configuration,\n",
    "            inputs=[annotated_img, gr.Textbox(value=\"config.json\")],\n",
    "            outputs=save_output\n",
    "        )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7884\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from gradio_image_annotation import image_annotator\n",
    "import easyocr\n",
    "import pygetwindow as gw\n",
    "import json\n",
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Capture screenshot of a selected window\n",
    "def capture_screenshot(window_title):\n",
    "    window = gw.getWindowsWithTitle(window_title)[0]\n",
    "    window.activate()\n",
    "    window_size = (window.left, window.top, window.width, window.height)\n",
    "    screenshot = ImageGrab.grab(window_size)\n",
    "    return screenshot, window_size\n",
    "\n",
    "# Run OCR and create bounding boxes\n",
    "def generate_bounding_boxes(image, use_ocr):\n",
    "    image_np = np.array(image)\n",
    "    boxes = []\n",
    "\n",
    "    if use_ocr:\n",
    "        results = reader.readtext(image_np)\n",
    "        for result in results:\n",
    "            top_left, bottom_right = result[0][0], result[0][2]\n",
    "            box = {\n",
    "                'xmin': int(top_left[0]),\n",
    "                'ymin': int(top_left[1]),\n",
    "                'xmax': int(bottom_right[0]),\n",
    "                'ymax': int(bottom_right[1]),\n",
    "                'label': result[1]\n",
    "            }\n",
    "            boxes.append(box)\n",
    "\n",
    "    return {'image': image_np, 'boxes': boxes}\n",
    "\n",
    "# Save configuration to a file\n",
    "def save_configuration(window_title, window_size, annotations, filename):\n",
    "    configurations = {\n",
    "        window_title: {\n",
    "            'window_size': window_size,\n",
    "            'annotations': annotations['boxes']\n",
    "        }\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(configurations, f)\n",
    "    return f\"Configuration saved to {filename}\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Windows Screenshot Annotation and Keystroke Execution\")\n",
    "\n",
    "    # Step 1: Select Window and Capture Screenshot\n",
    "    window_dropdown = gr.Dropdown(\n",
    "        choices=[w.title for w in gw.getAllWindows() if w.title],\n",
    "        label=\"Select Window\"\n",
    "    )\n",
    "    capture_button = gr.Button(\"Capture Screenshot\")\n",
    "    image_output = gr.Image(label=\"Captured Screenshot\", type=\"pil\")\n",
    "\n",
    "    # Step 2: Display and Annotate Image\n",
    "    use_ocr = gr.Checkbox(label=\"Use OCR to Detect Text\")\n",
    "    annotator = image_annotator(label=\"Annotate Screenshot\", label_list=[\"Text Region\"], label_colors=[(0, 255, 0)])\n",
    "\n",
    "    # Hidden state for storing window size\n",
    "    window_size_state = gr.State()\n",
    "\n",
    "    # Step 3: Save Configuration\n",
    "    filename_input = gr.Textbox(label=\"Filename to Save Configuration\")\n",
    "    save_button = gr.Button(\"Save Configuration\")\n",
    "    save_output = gr.Textbox(label=\"Save Output\")\n",
    "\n",
    "    # Capture screenshot and populate window size state\n",
    "    def capture_and_process(window_title, use_ocr):\n",
    "        screenshot, window_size = capture_screenshot(window_title)\n",
    "        image_data = generate_bounding_boxes(screenshot, use_ocr)\n",
    "        return screenshot, image_data, window_size\n",
    "\n",
    "    def save_annotations(annotations, filename, window_title, window_size):\n",
    "        return save_configuration(window_title, window_size, annotations, filename)\n",
    "\n",
    "    capture_button.click(\n",
    "        fn=capture_and_process,\n",
    "        inputs=[window_dropdown, use_ocr],\n",
    "        outputs=[image_output, annotator, window_size_state]\n",
    "    )\n",
    "\n",
    "    save_button.click(\n",
    "        fn=save_annotations,\n",
    "        inputs=[annotator, filename_input, window_dropdown, window_size_state],\n",
    "        outputs=save_output\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
